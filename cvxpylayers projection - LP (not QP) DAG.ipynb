{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CVXPyLayers - DAG w LP + L2 Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cvxpylayers.torch import CvxpyLayer\n",
    "import torch\n",
    "import cvxpy as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define convex optimization model\n",
    "num_n = 5\n",
    "num_e = 5\n",
    "e_out = [\n",
    "    [0, 1],\n",
    "    [2, 3],\n",
    "    [4],\n",
    "    [],\n",
    "    [],\n",
    "]\n",
    "e_in = [\n",
    "    [],\n",
    "    [0],\n",
    "    [1],\n",
    "    [2, 4],\n",
    "    [3],\n",
    "]\n",
    "\n",
    "n = cp.Variable(num_n)\n",
    "e = cp.Variable(num_e)\n",
    "s_in = cp.Parameter(1)\n",
    "s_out = cp.Variable(2)\n",
    "e_hat = cp.Parameter(num_e)\n",
    "\n",
    "R = 2.0\n",
    "# objective = cp.norm2(e-e_hat)\n",
    "objective = -1*e_hat.T@e + R*cp.norm2(e)\n",
    "bound_constraints = [e >= 0, e <= 1]\n",
    "flow_constraints = [\n",
    "    s_in[0] - e[0] - e[1] == 0,\n",
    "    e[0] - e[2] - e[3] == 0,\n",
    "    e[1] - e[4] == 0,\n",
    "    e[2] + e[4] + s_out[0] == 0,\n",
    "    e[3] + s_out[1] == 0,\n",
    "    \n",
    "]\n",
    "source_sink_constraints = [\n",
    "    s_in[0] + s_out[0] + s_out[1] == 0,\n",
    "]\n",
    "constraints = bound_constraints + flow_constraints + source_sink_constraints\n",
    "\n",
    "prob = cp.Problem(objective=cp.Minimize(objective), constraints=constraints)\n",
    "dag_proj_layer = CvxpyLayer(problem=prob, parameters=[e_hat, s_in], variables=[e, s_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5714, 0.4286, 0.5332, 0.0383, 0.4286],\n",
       "       grad_fn=<_CvxpyLayerFnFnBackward>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# layer(torch.Tensor([1.0]), torch.Tensor([1.0, 0.5]))\n",
    "path_true = torch.Tensor([1.0, 0.0, 0.0, 1.0, 0.0])\n",
    "e_arg = torch.Tensor([1.5, 1.0, 1.0, 0.0, 1.0])\n",
    "e_arg.requires_grad = True\n",
    "s_in_arg = torch.tensor([1.0])\n",
    "e_res, s_res = dag_proj_layer(e_arg, s_in_arg)\n",
    "loss = torch.norm(e_res - path_true)\n",
    "loss.backward()\n",
    "e_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5.7143e-01, 4.2857e-01, 5.3315e-01, 3.8278e-02, 4.2857e-01],\n",
       "         [1.0000e+00, 1.0000e+00, 1.0000e+00, 2.5964e-10, 1.0000e+00]]),\n",
       " tensor([[-9.6172e-01, -3.8277e-02],\n",
       "         [-2.0000e+00, -2.5143e-10]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dag_proj_layer(torch.Tensor([e_arg.tolist(), e_arg.tolist()]), torch.Tensor([[1.0], [2.0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 5])\n",
      "torch.Size([128, 1])\n"
     ]
    }
   ],
   "source": [
    "dtype = torch.double\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = \"cpu\"\n",
    "\n",
    "kwargs = {\"dtype\": dtype, \"device\": device}\n",
    "\n",
    "DIM = 5\n",
    "\n",
    "# We initialize a random tensor\n",
    "x = torch.rand([128, DIM]).to(**kwargs)\n",
    "print(x.shape)\n",
    "source = torch.ones(x.shape[0], 1).to(**kwargs)\n",
    "print(source.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 1., 0.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Turn its grad on, since we will change this tensor to minimize our loss\n",
    "x.requires_grad = True\n",
    "y_true = torch.Tensor([1.0, 0.0, 0.0, 1.0, 0.0]).to(**kwargs)\n",
    "\n",
    "print(y_true)\n",
    "\n",
    "# Initialize an SGD optimizer and do 200 steps\n",
    "optim = torch.optim.Adam([x], 1.0)\n",
    "# optim = torch.optim.LBFGS([x], lr=1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294.5468563408916\n",
      "1.084792829747162 2.4574028216302395\n",
      "2.130859157107358\n",
      "0.010886139049883291 1.4729430384787325\n",
      "3.3741665058101656e-05\n",
      "1.4026939905216687e-07 0.8048956090289476\n",
      "0.000735745340106364\n",
      "2.8467565811515646e-06 0.2884954141650119\n",
      "0.0010323381148076647\n",
      "4.017177457085587e-06 -0.13450568658221435\n",
      "0.0009104161244135732\n",
      "3.64385545052734e-06 -0.49203552447066495\n",
      "0.000850466354221736\n",
      "3.618872125443003e-06 -0.8001781947872023\n",
      "0.0010324171423726498\n",
      "4.386144375576987e-06 -1.0692795110388014\n",
      "0.001131951184123499\n",
      "4.822086260605543e-06 -1.3065075481068045\n",
      "0.0011340416491941153\n",
      "4.781860065437125e-06 -1.517102126857707\n",
      "0.0008468956377049555\n",
      "3.5563269355091067e-06 -1.7050516102331743\n",
      "0.0010447172125133035\n",
      "4.292194414994458e-06 -1.8734887336175303\n",
      "SGD has run???\n",
      "TIMES:  0 0\n",
      "Wall time: 11.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "import time\n",
    "BASE = 1\n",
    "\n",
    "fwd = 0\n",
    "bwd = 0\n",
    "\n",
    "dag_proj, _ = dag_proj_layer(x, source)\n",
    "loss = torch.norm(dag_proj - y_true, dim=-1).mean()\n",
    "#         print(perturbed_x)\n",
    "#         print(dag_proj[:10,:7])\n",
    "print(torch.abs(dag_proj - y_true).sum().item())\n",
    "print(loss.item(), torch.sum(x, dim=-1).mean().item())\n",
    "\n",
    "for iteration in range(10*BASE+1):\n",
    "    \n",
    "    def closure():\n",
    "        optim.zero_grad()\n",
    "        start = time.time()\n",
    "        dag_proj, _ = dag_proj_layer(x, source)\n",
    "        end = time.time()\n",
    "#         fwd += end - start\n",
    "        loss = torch.norm(dag_proj - y_true, dim=-1).mean()\n",
    "    #     + torch.norm(dag_proj - x)\n",
    "    #     + torch.maximum(\n",
    "    #         torch.norm(x, dim=-1) - torch.Tensor([6]).to(**kwargs), torch.Tensor([0]).to(**kwargs)\n",
    "    #     ).mean()\n",
    "        start = time.time()\n",
    "        loss.backward()\n",
    "        end = time.time()\n",
    "#         bwd += end - start  \n",
    "        return loss\n",
    "    optim.step(closure)\n",
    "    if iteration % BASE== 0:\n",
    "        dag_proj, _ = dag_proj_layer(x, source)\n",
    "        loss = torch.norm(dag_proj - y_true, dim=-1).mean()\n",
    "#         print(perturbed_x)\n",
    "#         print(dag_proj[:10,:7])\n",
    "        print(torch.abs(dag_proj - y_true).sum().item())\n",
    "        print(loss.item(), torch.sum(x, dim=-1).mean().item())\n",
    "        \n",
    "print(\"SGD has run???\")\n",
    "print(\"TIMES: \", fwd, bwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([128.,   0.,   0., 128.,   0.], dtype=torch.float64,\n",
       "       grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.round(dag_proj).sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
