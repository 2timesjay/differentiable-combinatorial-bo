{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perturbations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.3185e-01, 3.7064e-01, 7.6091e-01,  ..., 7.2449e-01, 4.0909e-01,\n",
      "         3.6302e-01],\n",
      "        [5.4926e-01, 9.0616e-01, 3.4756e-01,  ..., 9.3212e-02, 9.2029e-01,\n",
      "         7.0653e-02],\n",
      "        [7.5976e-01, 8.9371e-01, 1.2690e-01,  ..., 9.3196e-01, 7.1579e-04,\n",
      "         3.8021e-01],\n",
      "        ...,\n",
      "        [6.4389e-01, 5.8120e-01, 4.3260e-01,  ..., 4.4259e-02, 4.7809e-01,\n",
      "         4.1155e-01],\n",
      "        [7.4787e-01, 6.2935e-01, 2.1095e-02,  ..., 5.0277e-01, 4.2797e-01,\n",
      "         6.3522e-01],\n",
      "        [7.8070e-01, 6.5361e-01, 9.7238e-01,  ..., 7.4369e-01, 4.3411e-01,\n",
      "         6.5070e-01]], dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from perturbations import perturbed\n",
    "\n",
    "dtype = torch.double\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = \"cpu\"\n",
    "\n",
    "kwargs = {\"dtype\": dtype, \"device\": device}\n",
    "\n",
    "DEPTH = 4\n",
    "DIM = 2**DEPTH - 1\n",
    "\n",
    "path_inds = torch.zeros(DEPTH, DIM).long()\n",
    "path_inds[0] = torch.arange(start=0, end=DIM).long()\n",
    "path_inds[1] = ((path_inds[0]-1)/2).long()\n",
    "path_inds[2] = ((path_inds[1]-1)/2).long()\n",
    "path_inds[3] = ((path_inds[2]-1)/2).long()\n",
    "\n",
    "def best_path(inputs):\n",
    "    \"\"\"Returns the ranks of the input values among the given axis.\"\"\"\n",
    "    scores = inputs[..., path_inds].sum(dim=-2).squeeze(dim=-2)\n",
    "    best_scores_ind = scores[..., int(DIM/2):DIM].argmax(dim=-1, keepdim=True) + int(DIM/2)\n",
    "    best_path = torch.zeros_like(inputs)\n",
    "    # This handling of best_path_inds doesn't quite work as intended with 3+ dim input\n",
    "    best_path_inds = path_inds[...,best_scores_ind].squeeze(-1).transpose(-2, -1)\n",
    "    best_path.scatter_(dim=-1, index=best_path_inds, value=1.0)\n",
    "    return best_path\n",
    "\n",
    "# We initialize a random tensor\n",
    "x = torch.rand([128, DIM]).to(**kwargs)\n",
    "print(x)\n",
    "\n",
    "best_path(torch.rand(10, DIM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initially, the values in our tensor do not result in the desired argsort\n",
      "tensor([[1., 0., 1.,  ..., 1., 0., 0.],\n",
      "        [1., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [1., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 1.,  ..., 1., 0., 0.]], dtype=torch.float64)\n",
      "tensor([1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "# Turn its grad on, since we will change this tensor to minimize our loss\n",
    "x.requires_grad = True\n",
    "y_true = torch.Tensor([1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n",
    "\n",
    "print(\"Initially, the values in our tensor do not result in the desired argsort\")\n",
    "print(best_path(x))\n",
    "print(y_true)\n",
    "\n",
    "torch.norm(perturbed(best_path, device=device)(x) - y_true, dim=-1)\n",
    "\n",
    "# FenchelYoungLoss(ranks, device=device)(y_true, x)\n",
    "\n",
    "# Initialize an SGD optimizer and do 200 steps\n",
    "optim = torch.optim.SGD([x], 1.0)\n",
    "# optim = torch.optim.LBFGS([x], .01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "530.0\n",
      "1.544906080701755\n",
      "402.0\n",
      "1.3803906936763828\n",
      "282.0\n",
      "1.2114477780853492\n",
      "220.0\n",
      "1.0502806231823238\n",
      "184.0\n",
      "0.912907864504493\n",
      "164.0\n",
      "0.7998588342977688\n",
      "132.0\n",
      "0.7062404965477833\n",
      "118.0\n",
      "0.633140877323443\n",
      "102.0\n",
      "0.5636766537875812\n",
      "80.0\n",
      "0.49754726178344844\n",
      "78.0\n",
      "0.46107268092121706\n",
      "SGD has run???\n",
      "Wall time: 1.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "BASE = 10\n",
    "\n",
    "for iteration in range(10*BASE+1):\n",
    "    def closure():\n",
    "        optim.zero_grad()\n",
    "    #     criterion = FenchelYoungLoss(ranks, sigma=0.25, device=device)\n",
    "    #     loss = criterion(x, y_true).sum()\n",
    "        perturbed_x = perturbed(best_path, num_samples=100, sigma=0.25, noise='gumbel', device=device)(x)\n",
    "        loss = torch.norm(perturbed_x - y_true, dim=-1).mean()\n",
    "        loss.backward()\n",
    "        return loss\n",
    "    optim.step(closure)\n",
    "    if iteration % BASE== 0:\n",
    "        perturbed_x = perturbed(best_path, num_samples=100, sigma=0.25, noise='gumbel', device=device)(x)\n",
    "        loss = torch.norm(perturbed_x - y_true, dim=-1).mean()\n",
    "#         print(perturbed_x)\n",
    "        print(torch.abs(best_path(x) - y_true).sum().item())\n",
    "        print(loss.item())\n",
    "        \n",
    "print(\"SGD has run???\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([128., 126.,   2., 121.,   5.,   2.,   0.,  98.,  23.,   5.,   0.,   0.,\n",
       "          2.,   0.,   0.], dtype=torch.float64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_path(x).sum(dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perturbed Fixed Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9520, 0.6853, 0.0169,  ..., 0.3967, 0.9420, 0.0465],\n",
      "        [0.6383, 0.7843, 0.7522,  ..., 0.3941, 0.5742, 0.5866],\n",
      "        [0.6394, 0.1132, 0.9993,  ..., 0.0220, 0.2934, 0.2692],\n",
      "        ...,\n",
      "        [0.7485, 0.5366, 0.1259,  ..., 0.7921, 0.7855, 0.4668],\n",
      "        [0.4089, 0.8890, 0.4769,  ..., 0.0082, 0.0758, 0.3279],\n",
      "        [0.8342, 0.1238, 0.1844,  ..., 0.4754, 0.7336, 0.9265]],\n",
      "       dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from perturbations import fixed_noise_perturbed, get_presampled_noises\n",
    "\n",
    "dtype = torch.double\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = \"cpu\"\n",
    "\n",
    "kwargs = {\"dtype\": dtype, \"device\": device}\n",
    "\n",
    "DEPTH = 4\n",
    "DIM = 2**DEPTH - 1\n",
    "\n",
    "path_inds = torch.zeros(DEPTH, DIM).long()\n",
    "path_inds[0] = torch.arange(start=0, end=DIM).long()\n",
    "path_inds[1] = ((path_inds[0]-1)/2).long()\n",
    "path_inds[2] = ((path_inds[1]-1)/2).long()\n",
    "path_inds[3] = ((path_inds[2]-1)/2).long()\n",
    "\n",
    "def best_path(inputs):\n",
    "    \"\"\"Returns the ranks of the input values among the given axis.\"\"\"\n",
    "    scores = inputs[..., path_inds].sum(dim=-2).squeeze(dim=-2)\n",
    "    best_scores_ind = scores[..., int(DIM/2):DIM].argmax(dim=-1, keepdim=True) + int(DIM/2)\n",
    "    best_path = torch.zeros_like(inputs)\n",
    "    # This handling of best_path_inds doesn't quite work as intended with 3+ dim input\n",
    "    best_path_inds = path_inds[...,best_scores_ind].squeeze(-1).transpose(-2, -1)\n",
    "    best_path.scatter_(dim=-1, index=best_path_inds, value=1.0)\n",
    "    return best_path\n",
    "\n",
    "# We initialize a random tensor\n",
    "x = torch.rand([128, DIM]).to(**kwargs)\n",
    "print(x)\n",
    "\n",
    "best_path(torch.rand(10, DIM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initially, the values in our tensor do not result in the desired argsort\n",
      "tensor([[1., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [1., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 1.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "tensor([1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "# Turn its grad on, since we will change this tensor to minimize our loss\n",
    "x.requires_grad = True\n",
    "y_true = torch.Tensor([1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n",
    "\n",
    "print(\"Initially, the values in our tensor do not result in the desired argsort\")\n",
    "print(best_path(x))\n",
    "print(y_true)\n",
    "\n",
    "presampled_noises = get_presampled_noises(x.shape, num_samples=1000, noise=\"normal\")\n",
    "torch.norm(\n",
    "    fixed_noise_perturbed(\n",
    "        best_path, \n",
    "        presampled_noises=presampled_noises, \n",
    "        num_samples=1000, \n",
    "        sigma=0.25, \n",
    "        device=device\n",
    "    )(x) - y_true, \n",
    "    dim=-1\n",
    ")\n",
    "\n",
    "# FenchelYoungLoss(ranks, device=device)(y_true, x)\n",
    "\n",
    "# Initialize an SGD optimizer and do 200 steps\n",
    "optim = torch.optim.SGD([x], 1.0)\n",
    "# optim = torch.optim.LBFGS([x], .1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 14 is out of bounds for dimension 0 with size 14",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\optim\\lbfgs.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    309\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m         \u001b[1;31m# evaluate initial f(x) and df/dx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 311\u001b[1;33m         \u001b[0morig_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[0mcurrent_evals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36mclosure\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\PythonProjects\\repos\\optimization-transforms-botorch\\perturbations.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(input_tensor, *args)\u001b[0m\n\u001b[0;32m    329\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_input_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 331\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mPerturbedFunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    332\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PythonProjects\\repos\\optimization-transforms-botorch\\perturbations.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(ctx, input_tensor, *args)\u001b[0m\n\u001b[0;32m    285\u001b[0m                 \u001b[0mperturbed_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mperturbed_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflat_batch_dim_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m                 \u001b[1;31m# Calls user-defined function in a perturbation agnostic manner.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 287\u001b[1;33m                 \u001b[0mperturbed_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mperturbed_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    288\u001b[0m                 \u001b[1;31m# [NB, D1, ..., Dk] ->  [N, B, D1, ..., Dk].\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m                 \u001b[0mperturbed_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mperturbed_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mperturbed_input_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-55398812b0a7>\u001b[0m in \u001b[0;36mbest_path\u001b[1;34m(inputs)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mbest_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;34m\"\"\"Returns the ranks of the input values among the given axis.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath_inds\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[0mbest_scores_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDIM\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mDIM\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDIM\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mbest_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 14 is out of bounds for dimension 0 with size 14"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "BASE = 10\n",
    "\n",
    "N_SAMPLES = 1000\n",
    "\n",
    "for iteration in range(10*BASE+1):    \n",
    "    presampled_noises = get_presampled_noises(x.shape, num_samples=N_SAMPLES, noise=\"normal\")\n",
    "    def closure():\n",
    "        optim.zero_grad()\n",
    "    #     criterion = FenchelYoungLoss(ranks, sigma=0.25, device=device)\n",
    "    #     loss = criterion(x, y_true).sum()\n",
    "        perturbed_x = fixed_noise_perturbed(\n",
    "            best_path, \n",
    "            presampled_noises=presampled_noises, \n",
    "            num_samples=N_SAMPLES, \n",
    "            sigma=0.25, \n",
    "            device=device\n",
    "        )(x)\n",
    "        loss = torch.norm(perturbed_x - y_true, dim=-1).mean()\n",
    "        loss.backward()\n",
    "        return loss\n",
    "    optim.step(closure)\n",
    "    if iteration % BASE== 0:\n",
    "        perturbed_x = fixed_noise_perturbed(\n",
    "            best_path, \n",
    "            presampled_noises=presampled_noises, \n",
    "            num_samples=N_SAMPLES, \n",
    "            sigma=0.25, \n",
    "            device=device\n",
    "        )(x)\n",
    "        loss = torch.norm(perturbed_x - y_true, dim=-1).mean()\n",
    "#         print(perturbed_x)\n",
    "        print(torch.abs(best_path(x) - y_true).sum().item())\n",
    "        print(loss.item())\n",
    "        \n",
    "print(\"SGD has run???\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CVXPyLayers - DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cvxpylayers.torch import CvxpyLayer\n",
    "import torch\n",
    "import cvxpy as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define convex optimization model\n",
    "num_n = 5\n",
    "num_e = 5\n",
    "e_out = [\n",
    "    [0, 1],\n",
    "    [2, 3],\n",
    "    [4],\n",
    "    [],\n",
    "    [],\n",
    "]\n",
    "e_in = [\n",
    "    [],\n",
    "    [0],\n",
    "    [1],\n",
    "    [2, 4],\n",
    "    [3],\n",
    "]\n",
    "\n",
    "n = cp.Variable(num_n)\n",
    "e = cp.Variable(num_e)\n",
    "s_in = cp.Parameter(1)\n",
    "s_out = cp.Variable(2)\n",
    "e_hat = cp.Parameter(num_e)\n",
    "\n",
    "objective = cp.norm2(e-e_hat)\n",
    "bound_constraints = [e >= 0, e <= 1]\n",
    "flow_constraints = [\n",
    "    s_in[0] - e[0] - e[1] == 0,\n",
    "    e[0] - e[2] - e[3] == 0,\n",
    "    e[1] - e[4] == 0,\n",
    "    e[2] + e[4] + s_out[0] == 0,\n",
    "    e[3] + s_out[1] == 0,\n",
    "    \n",
    "]\n",
    "source_sink_constraints = [\n",
    "    s_in[0] + s_out[0] + s_out[1] == 0,\n",
    "]\n",
    "constraints = bound_constraints + flow_constraints + source_sink_constraints\n",
    "\n",
    "prob = cp.Problem(objective=cp.Minimize(objective), constraints=constraints)\n",
    "dag_proj_layer = CvxpyLayer(problem=prob, parameters=[e_hat, s_in], variables=[e, s_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6.2500e-01,  3.7500e-01,  6.2500e-01, -1.2694e-10,  3.7500e-01],\n",
       "       grad_fn=<_CvxpyLayerFnFnBackward>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# layer(torch.Tensor([1.0]), torch.Tensor([1.0, 0.5]))\n",
    "path_true = torch.Tensor([1.0, 0.0, 0.0, 1.0, 0.0])\n",
    "e_arg = torch.Tensor([1.5, 1.0, 1.0, 0.0, 1.0])\n",
    "e_arg.requires_grad = True\n",
    "s_in_arg = torch.tensor([1.0])\n",
    "e_res, s_res = dag_proj_layer(e_arg, s_in_arg)\n",
    "loss = torch.norm(e_res - path_true)\n",
    "loss.backward()\n",
    "e_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 6.2500e-01,  3.7500e-01,  6.2500e-01, -1.2694e-10,  3.7500e-01],\n",
       "         [ 1.0000e+00,  1.0000e+00,  9.9997e-01,  3.6081e-05,  1.0000e+00]]),\n",
       " tensor([[-1.0000e+00,  1.6819e-10],\n",
       "         [-2.0000e+00, -3.3548e-05]]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dag_proj_layer(torch.Tensor([e_arg.tolist(), e_arg.tolist()]), torch.Tensor([[1.0], [2.0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 5])\n",
      "torch.Size([128, 1])\n"
     ]
    }
   ],
   "source": [
    "dtype = torch.double\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = \"cpu\"\n",
    "\n",
    "kwargs = {\"dtype\": dtype, \"device\": device}\n",
    "\n",
    "DIM = 5\n",
    "\n",
    "# We initialize a random tensor\n",
    "x = torch.rand([128, DIM]).to(**kwargs)\n",
    "print(x.shape)\n",
    "source = torch.ones(x.shape[0], 1).to(**kwargs)\n",
    "print(source.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 1., 0.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Turn its grad on, since we will change this tensor to minimize our loss\n",
    "x.requires_grad = True\n",
    "y_true = torch.Tensor([1.0, 0.0, 0.0, 1.0, 0.0]).to(**kwargs)\n",
    "\n",
    "print(y_true)\n",
    "\n",
    "# Initialize an SGD optimizer and do 200 steps\n",
    "optim = torch.optim.Adam([x], 1.0)\n",
    "# optim = torch.optim.LBFGS([x], lr=1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.00039860204829\n",
      "0.15925753900266398 1.8224354377598138\n",
      "30.001746417708592\n",
      "0.15926332809799687 1.3308338987417847\n",
      "30.002646526672727\n",
      "0.15926733196860007 0.9480586989442407\n",
      "30.002053412962134\n",
      "0.15926452590498824 0.6352807158939697\n",
      "30.001823684527313\n",
      "0.15926320713274444 0.37016834605050386\n",
      "30.002076394949967\n",
      "0.15926378584744097 0.14168258562392505\n",
      "30.002683010649783\n",
      "0.1592664223676385 -0.058295641796905\n",
      "30.002731352352562\n",
      "0.1592665344007294 -0.23461336999044588\n",
      "30.003660802340036\n",
      "0.15926983285893184 -0.39127463174818333\n",
      "30.00314438494598\n",
      "0.15926810810088876 -0.5311904658046104\n",
      "30.00214102161243\n",
      "0.15926432932356316 -0.6565962140890227\n",
      "SGD has run???\n",
      "TIMES:  0 0\n",
      "Wall time: 10.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "import time\n",
    "BASE = 1\n",
    "\n",
    "fwd = 0\n",
    "bwd = 0\n",
    "for iteration in range(10*BASE+1):\n",
    "    \n",
    "    def closure():\n",
    "        optim.zero_grad()\n",
    "        start = time.time()\n",
    "        dag_proj, _ = dag_proj_layer(x, source)\n",
    "        end = time.time()\n",
    "#         fwd += end - start\n",
    "        loss = torch.norm(dag_proj - y_true, dim=-1).mean()\n",
    "    #     + torch.norm(dag_proj - x)\n",
    "    #     + torch.maximum(\n",
    "    #         torch.norm(x, dim=-1) - torch.Tensor([6]).to(**kwargs), torch.Tensor([0]).to(**kwargs)\n",
    "    #     ).mean()\n",
    "        start = time.time()\n",
    "        loss.backward()\n",
    "        end = time.time()\n",
    "#         bwd += end - start  \n",
    "        return loss\n",
    "    optim.step(closure)\n",
    "    if iteration % BASE== 0:\n",
    "        dag_proj, _ = dag_proj_layer(x, source)\n",
    "        loss = torch.norm(dag_proj - y_true, dim=-1).mean()\n",
    "#         print(perturbed_x)\n",
    "#         print(dag_proj[:10,:7])\n",
    "        print(torch.abs(dag_proj - y_true).sum().item())\n",
    "        print(loss.item(), torch.sum(x, dim=-1).mean().item())\n",
    "        \n",
    "print(\"SGD has run???\")\n",
    "print(\"TIMES: \", fwd, bwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([128.,   0.,  18., 110.,   0.], dtype=torch.float64,\n",
       "       grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.round(dag_proj).sum(dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CVXPyLayers - Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.double\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = \"cpu\"\n",
    "\n",
    "kwargs = {\"dtype\": dtype, \"device\": device}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define convex optimization model\n",
    "num_e = 14\n",
    "num_sinks = 8\n",
    "e = cp.Variable(num_e)\n",
    "s_in = cp.Parameter(1)\n",
    "s_out = cp.Variable(num_sinks)\n",
    "e_hat = cp.Parameter(num_e)\n",
    "\n",
    "objective = cp.norm2(e-e_hat)\n",
    "bound_constraints = [e >= 0, e <= 1]\n",
    "flow_constraints = [\n",
    "    e[0] - e[2] - e[3] == 0,\n",
    "    e[1] - e[4] - e[5] == 0,\n",
    "    e[2] - e[6] - e[7] == 0,\n",
    "    e[3] - e[8] - e[9] == 0,\n",
    "    e[4] - e[10] - e[11] == 0,\n",
    "    e[5] - e[12] - e[13] == 0,\n",
    "] + [\n",
    "    e[6+i] + s_out[i] == 0\n",
    "    for i in range(num_sinks)\n",
    "]\n",
    "source_sink_constraints = [\n",
    "    s_in[0] + cp.sum(s_out) == 0,\n",
    "]\n",
    "constraints = bound_constraints + flow_constraints + source_sink_constraints\n",
    "\n",
    "prob = cp.Problem(objective=cp.Minimize(objective), constraints=constraints)\n",
    "dag_proj_layer = CvxpyLayer(problem=prob, parameters=[e_hat, s_in], variables=[e, s_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 14])\n",
      "torch.Size([128, 1])\n"
     ]
    }
   ],
   "source": [
    "DIM = 14\n",
    "\n",
    "# We initialize a random tensor\n",
    "x = torch.rand([128, DIM]).to(**kwargs)\n",
    "print(x.shape)\n",
    "source = torch.ones(x.shape[0], 1).to(**kwargs)\n",
    "print(source.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n",
      "tensor(1.5538, dtype=torch.float64, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Turn its grad on, since we will change this tensor to minimize our loss\n",
    "x.requires_grad = True\n",
    "y_true = torch.Tensor([1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n",
    "\n",
    "# print(best_path(x))\n",
    "print(y_true)\n",
    "\n",
    "dag_proj, _ = dag_proj_layer(x, source) \n",
    "print(torch.norm(dag_proj - y_true, dim=-1).mean())\n",
    "\n",
    "# Initialize an SGD optimizer and do 200 steps\n",
    "# optim = torch.optim.SGD([x], lr=10.0)\n",
    "optim = torch.optim.LBFGS([x], lr=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106.00091032137317\n",
      "0.520852935131989 6.954080244383761\n",
      "106.00091032137317\n",
      "0.520852935131989 6.954080244383761\n",
      "106.00091032137317\n",
      "0.520852935131989 6.954080244383761\n",
      "106.00091032137317\n",
      "0.520852935131989 6.954080244383761\n",
      "106.00091032137317\n",
      "0.520852935131989 6.954080244383761\n",
      "106.00091032137317\n",
      "0.520852935131989 6.954080244383761\n",
      "106.00091032137317\n",
      "0.520852935131989 6.954080244383761\n",
      "106.00091032137317\n",
      "0.520852935131989 6.954080244383761\n",
      "106.00091032137317\n",
      "0.520852935131989 6.954080244383761\n",
      "106.00091032137317\n",
      "0.520852935131989 6.954080244383761\n",
      "106.00091032137317\n",
      "0.520852935131989 6.954080244383761\n",
      "SGD has run???\n",
      "TIMES:  0 0\n",
      "Wall time: 17.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "BASE = 1\n",
    "\n",
    "fwd = 0\n",
    "bwd = 0\n",
    "for iteration in range(10*BASE+1):\n",
    "    \n",
    "    def closure():\n",
    "        optim.zero_grad()\n",
    "        start = time.time()\n",
    "        dag_proj, _ = dag_proj_layer(x, source)\n",
    "        end = time.time()\n",
    "#         fwd += end - start\n",
    "        loss = torch.norm(dag_proj - y_true, dim=-1).mean()\n",
    "    #     + torch.norm(dag_proj - x)\n",
    "    #     + torch.maximum(\n",
    "    #         torch.norm(x, dim=-1) - torch.Tensor([6]).to(**kwargs), torch.Tensor([0]).to(**kwargs)\n",
    "    #     ).mean()\n",
    "        start = time.time()\n",
    "        loss.backward()\n",
    "        end = time.time()\n",
    "#         bwd += end - start  \n",
    "        return loss\n",
    "    optim.step(closure)\n",
    "    if iteration % BASE== 0:\n",
    "        dag_proj, _ = dag_proj_layer(x, source)\n",
    "        loss = torch.norm(dag_proj - y_true, dim=-1).mean()\n",
    "#         print(perturbed_x)\n",
    "#         print(dag_proj[:10,:7])\n",
    "        print(torch.abs(dag_proj - y_true).sum().item())\n",
    "        print(loss.item(), torch.sum(x, dim=-1).mean().item())\n",
    "        \n",
    "print(\"SGD has run???\")\n",
    "print(\"TIMES: \", fwd, bwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.9357e-01, 9.0108e-02, 2.0178e+01, 2.0237e+01, 2.7333e+01, 7.2641e-01,\n",
       "        2.6924e+01, 2.0451e+01, 2.1102e+01, 2.2105e+01, 2.1090e+01, 2.4846e+01,\n",
       "        1.1288e-01, 2.1883e+01, 2.6872e+01, 5.0422e-01, 2.3302e-01, 1.0843e-01,\n",
       "        1.6690e-01, 2.0878e+01, 3.4643e-01, 1.9815e+01, 6.9619e-02, 1.9880e+01,\n",
       "        1.9423e+01, 2.4565e+01, 2.1004e+01, 2.1605e+01, 4.8361e-01, 2.1652e+01,\n",
       "        2.5763e+01, 2.9220e-01, 2.5144e+01, 2.2408e+01, 2.1852e+01, 4.7119e-01,\n",
       "        2.6044e+01, 2.1563e+01, 2.4398e+01, 1.5851e-01, 2.0480e+01, 3.2645e-03,\n",
       "        2.3797e+01, 1.8901e+01, 2.5515e+01, 2.2012e+01, 2.0657e+01, 9.4815e-02,\n",
       "        3.9029e-01, 2.4551e+01, 2.2940e+01, 3.6197e-01, 2.6178e+01, 2.3106e+01,\n",
       "        1.7896e+01, 3.2030e-01, 2.1907e+01, 1.8311e-01, 1.9685e+01, 2.0427e+01,\n",
       "        2.0640e-01, 2.0261e+01, 2.7306e-01, 2.2856e+01, 3.1585e-01, 1.0656e-01,\n",
       "        2.2077e+01, 2.0519e+01, 3.0591e-01, 2.0258e-01, 2.1737e+01, 2.2918e+01,\n",
       "        2.1432e+01, 2.0719e+01, 2.2451e+01, 2.3772e+01, 5.2961e-01, 2.2187e+01,\n",
       "        2.3668e+01, 4.6954e-01, 1.8858e-01, 2.0790e+01, 2.6218e+01, 2.2573e+01,\n",
       "        4.7082e-02, 2.2955e+01, 2.2903e+01, 2.4613e+01, 6.1301e-02, 2.1274e+01,\n",
       "        2.6690e-01, 2.3807e+01, 2.0614e+01, 2.3824e+01, 4.8167e-01, 2.3763e+01,\n",
       "        2.3829e+01, 2.4449e+01, 1.5664e-01, 1.2159e-01, 1.9229e+01, 2.1985e+01,\n",
       "        2.0666e+01, 2.1201e+01, 2.0604e+01, 7.1043e-02, 4.4509e-01, 2.1488e+01,\n",
       "        2.1395e+01, 2.2111e+01, 2.1108e+01, 2.1278e+01, 2.4234e+01, 2.2178e+01,\n",
       "        2.2240e+01, 2.1047e+01, 2.7006e+01, 2.5835e+01, 3.2051e-01, 2.1732e+01,\n",
       "        1.8559e-01, 2.0474e+01, 1.0073e-01, 1.2505e-01, 2.2013e+01, 1.4573e-01,\n",
       "        3.5047e-02, 2.0801e+01], dtype=torch.float64, grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000e+00,  1.0000e+00,  6.6653e-11],\n",
       "        [ 1.0000e+00,  1.6440e-10,  4.2515e-11],\n",
       "        [ 1.0000e+00,  9.9999e-01,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  3.0006e-12, -7.8576e-12],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00, -3.0783e-11],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  5.2019e-06,  5.5726e-06],\n",
       "        [ 9.9999e-01, -1.5839e-05, -6.6986e-06],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.8789e-09],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.8043e-11],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00, -2.0712e-11],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0702e-10],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00, -8.6108e-11],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  2.2384e-10, -6.7388e-12],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00, -2.4768e-11],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00, -1.9276e-11],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  9.9999e-01,  4.8571e-07],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.9877e-06],\n",
       "        [ 1.0000e+00,  9.4293e-11, -2.5907e-11],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.1158e-08],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  3.8890e-08],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  4.8593e-11],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  2.4726e-12],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00, -4.1915e-11,  2.9469e-11],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.1656e-11],\n",
       "        [ 1.0000e+00, -1.8476e-11,  9.1722e-11],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00, -4.0194e-10,  8.0699e-11],\n",
       "        [ 1.0000e+00,  1.0000e+00, -5.6817e-11],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  9.9999e-01,  2.8619e-06],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.4761e-10],\n",
       "        [ 1.0000e+00,  1.0000e+00, -3.5484e-10],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  6.8218e-11],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00, -1.2390e-10],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  7.7810e-11],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00, -1.1753e-10],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.5692e-10],\n",
       "        [ 1.0000e+00,  1.0000e+00, -4.7172e-09],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.2692e-06],\n",
       "        [ 1.0000e+00,  1.0000e+00, -1.4430e-10],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  9.9999e-01,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 9.9999e-01,  1.0000e+00, -4.7328e-06],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  8.5102e-11],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  2.1406e-10],\n",
       "        [ 1.0000e+00,  1.0000e+00, -2.2359e-10],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 9.9999e-01,  1.0000e+00,  1.6396e-05],\n",
       "        [ 9.9999e-01, -1.5085e-05, -8.7958e-07],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00]], dtype=torch.float64,\n",
       "       grad_fn=<IndexBackward>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dag_proj[:,[0,2,6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
